```python
import pandas as pd
import numpy as np

def heuristics_v2(df, lookback_period=10, spike_threshold=0.2, weight_on_spike=1.5, ema_span=5):
    # Calculate High-Low Difference
    df['High_Low_Diff'] = df['high'] - df['low']
    
    # Identify Volume Spikes
    df['Volume_Percentage_Change'] = df['volume'].pct_change()
    df['Spike_Indicator'] = (df['Volume_Percentage_Change'] > spike_threshold).astype(int)
    
    # Combine High-Low Difference and Volume Spikes
    df['High_Low_Adjusted'] = df['High_Low_Diff'] * df['Spike_Indicator']
    df['High_Low_Sum'] = df['High_Low_Adjusted'].rolling(window=lookback_period).sum()
    
    # Calculate Daily Log Return
    df['Daily_Log_Return'] = np.log(df['close'] / df['close'].shift(1))
    
    # Adjust Momentum for Volume Spikes
    df['Adjusted_Return'] = df['Daily_Log_Return'] * np.where(df['Spike_Indicator'] == 1, weight_on_spike, 1)
    
    # Smooth the Adjusted Returns with Exponential Moving Average
    df['Smoothed_Adjusted_Return'] = df['Adjusted_Return'].ewm(span=ema_span).mean()
    
    # Cumulative Momentum Factor
    df['Cumulative_Momentum_Factor'] = df['High_Low_Sum'] + df['Smoothed_Adjusted_Return']
    
    return df['Cumulative_Momentum_Factor']

# Example usage:
# df = pd.read_csv('your_data.csv', index_col='date', parse_dates=True)
# factor_values = heuristics_v2(df)
# print(factor_values)
```
