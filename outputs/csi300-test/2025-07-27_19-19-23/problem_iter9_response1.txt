```python
import pandas as pd
import numpy as np

def heuristics_v2(df, threshold=2.0, spike_weight=0.5, ema_span=10):
    # Calculate Daily Log Return
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    
    # Identify Volume and Price Spikes
    df['volume_zscore'] = (df['volume'] - df['volume'].rolling(window=30).mean()) / df['volume'].rolling(window=30).std()
    df['price_zscore'] = (df['high'] - df['low']) / ((df['high'] + df['low']).rolling(window=30).std())
    df['is_spike'] = (df['volume_zscore'].abs() > threshold) | (df['price_zscore'].abs() > threshold)
    
    # Adjust Momentum for Volume and Price Spikes
    df['adjusted_log_return'] = np.where(df['is_spike'], df['log_return'] * spike_weight, df['log_return'])
    
    # Smooth the Adjusted Returns using Exponential Moving Average
    df['smoothed_return'] = df['adjusted_log_return'].ewm(span=ema_span, min_periods=ema_span).mean()
    
    # Cumulative Momentum Factor
    df['cumulative_momentum'] = (df['smoothed_return'] + 1).cumprod().fillna(1)
    
    return df['cumulative_momentum']

# Example usage:
# data = pd.DataFrame({
#     'open': [100, 101, 102, 99, 100],
#     'high': [102, 103, 104, 101, 102],
#     'low': [98, 99, 100, 97, 98],
#     'close': [101, 102, 103, 100, 101],
#     'amount': [1000, 1500, 1200, 1300, 1400],
#     'volume': [10000, 15000, 12000, 13000, 14000]
# }, index=pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05']))

# factor_values = heuristics_v2(data)
# print(factor_values)
```
