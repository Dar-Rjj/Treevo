```python
def heuristics_v2(df: pd.DataFrame, macroeconomic_indicators: pd.DataFrame) -> pd.Series:
    # Calculate the 5-day, 20-day, and 60-day returns
    five_day_return = df['close'].pct_change(periods=5)
    twenty_day_return = df['close'].pct_change(periods=20)
    sixty_day_return = df['close'].pct_change(periods=60)

    # Calculate the 20-day and 60-day average volume
    avg_20_day_volume = df['volume'].rolling(window=20).mean()
    avg_60_day_volume = df['volume'].rolling(window=60).mean()

    # Calculate the 60-day relative strength compared to the 20-day
    rs_60_over_20 = df['close'].rolling(window=60).mean() / df['close'].rolling(window=20).mean()

    # Calculate the 20-day trend of the 5-day volume
    vol_trend = df['volume'].rolling(window=5).mean().pct_change(periods=20)

    # Calculate the 10-day and 30-day relative strength
    rs_30_over_10 = df['close'].rolling(window=30).mean() / df['close'].rolling(window=10).mean()

    # Calculate the adaptive volatility for 5-day, 20-day, and 60-day periods
    short_volatility = df['close'].rolling(window=5).std()
    long_volatility = df['close'].rolling(window=20).std()
    long_long_volatility = df['close'].rolling(window=60).std()

    # Calculate the volatility adjusted 5-day, 20-day, and 60-day returns
    vol_adj_five_day_return = five_day_return / (short_volatility + 1e-7)
    vol_adj_twenty_day_return = twenty_day_return / (long_volatility + 1e-7)
    vol_adj_sixty_day_return = sixty_day_return / (long_long_volatility + 1e-7)

    # Calculate the 14-day RSI
    delta = df['close'].diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    avg_gain = up.ewm(span=14, adjust=False).mean()
    avg_loss = down.ewm(span=14, adjust=False).mean()
    rs = avg_gain / (avg_loss + 1e-7)
    rsi = 100 - (100 / (1 + rs))

    # Dynamic weighting using machine learning
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    import numpy as np

    features = pd.concat([five_day_return, twenty_day_return, sixty_day_return], axis=1)
    target = df['close'].shift(-1).pct_change().dropna()
    features = features.dropna().align(target, join='inner')[0]
    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    weights = model.predict(features)

    weight_5 = weights[:, 0] / np.sum(weights, axis=1)
    weight_20 = weights[:, 1] / np.sum(weights, axis=1)
    weight_60 = weights[:, 2] / np.sum(weights, axis=1)

    # Exponential smoothing of the 5-day, 20-day, and 60-day returns
    exp_smoothed_five_day_return = five_day_return.ewm(alpha=0.2, adjust=False).mean()
    exp_smoothed_twenty_day_return = twenty_day_return.ewm(alpha=0.2, adjust=False).mean()
    exp_smoothed_sixty_day_return = sixty_day_return.ewm(alpha=0.2, adjust=False).mean()

    # Incorporate macroeconomic indicators
    macro_avg = macroeconomic_indicators.mean(axis=1)

    # Construct an alpha factor that combines multi-period returns, relative strength, and volume trends,
    # adjusting for adaptive volatility and incorporating RSI and macroeconomic indicators to enhance predictive power with dynamic weighting and exponential smoothing
    alpha_factor = (weight_5 * exp_smoothed_five_day_return + 
                    weight_20 * exp_smoothed_twenty_day_return + 
                    weight_60 * exp_smoothed_sixty_day_return) * \
                   (avg_20_day_volume / (avg_60_day_volume +
