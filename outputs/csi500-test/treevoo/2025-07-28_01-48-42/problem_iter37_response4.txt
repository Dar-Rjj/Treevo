```python
import pandas as pd
import numpy as np

def heuristics_v2(df):
    # Calculate daily return
    df['daily_return'] = (df['close'] - df['open']) / df['open']
    
    # Define a factor for daily log return
    df['log_return'] = np.log(df['close'] / df['open'])
    
    # Create a factor that calculates the cumulative log return over the past 5 days
    df['cumulative_log_return_5d'] = df['log_return'].rolling(window=5).sum()
    
    # Compute the 10-day moving average of the daily return
    df['moving_avg_10d'] = df['daily_return'].rolling(window=10).mean()
    
    # Calculate the difference between the current day's return and its 10-day moving average
    df['return_vs_moving_avg_10d'] = df['daily_return'] - df['moving_avg_10d']
    
    # Create a factor that measures the acceleration of returns by computing the difference in the 10-day moving average over consecutive days
    df['acceleration_10d'] = df['moving_avg_10d'].diff()
    
    # Compute the standard deviation of the past 20 days' daily returns to measure recent volatility
    df['volatility_20d'] = df['daily_return'].rolling(window=20).std()
    
    # Calculate the ratio of the current day's return to the recent volatility
    df['return_to_volatility_ratio'] = df['daily_return'] / df['volatility_20d']
    
    # Introduce a factor that measures the rolling correlation between the daily return and the recent volatility
    df['correlation_return_volatility'] = df['daily_return'].rolling(window=20).corr(df['volatility_20d'])
    
    # Create a factor as the ratio of todayâ€™s volume over the average volume of the last 20 days, multiplied by the daily return
    df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()
    df['volume_adjusted_return'] = df['volume_ratio'] * df['daily_return']
    
    # Introduce a threshold for the volume ratio to create a binary indicator when the volume is significantly higher than the average
    df['high_volume_day'] = (df['volume_ratio'] > 1.5).astype(int)
    
    # Enhance the binary factor by incorporating the direction and magnitude of the daily return on these high-volume days
    df['high_volume_return'] = df['high_volume_day'] * df['daily_return']
    
    # Compute the percentage range as (high - low) / close
    df['percentage_range'] = (df['high'] - df['low']) / df['close']
    
    # Combine the percentage range with the daily return to form a new factor
    df['range_return_factor'] = df['percentage_range'] * df['daily_return']
    
    # Create a factor that considers the interaction between the percentage range and the 10-day moving average of the daily return
    df['range_moving_avg_interaction'] = df['percentage_range'] * df['moving_avg_10d']
    
    # Introduce a factor that measures the ratio of the percentage range to the 10-day moving average of the percentage range
    df['range_ratio_to_moving_avg'] = df['percentage_range'] / df['percentage_range'].rolling(window=10).mean()
    
    # Identify days where the volume is above the 95th percentile of the past 30 days
    df['high_volume_flag'] = (df['volume'] > df['volume'].rolling(window=30).quantile(0.95)).astype(int)
    
    # For those days, flag them and create a binary factor
    df['high_volume_binary'] = df['high_volume_flag'] * df['daily_return']
    
    # Determine if there is a gap up or down (open - previous close)
    df['gap'] = df['open'] - df['close'].shift(1)
    
    # Create a factor based on the magnitude and direction of these gaps, combined with the next day's return
    df['gap_factor'] = df['gap'] * df['daily_return'].shift(-1)
    
    # Extend the factor to include the impact of consecutive gaps over a 10-day period
    df['consecutive_gaps_10d'] = df['gap'].rolling(window=10).sum() * df['daily_return']
    
    # Introduce a factor that measures the frequency and magnitude of gaps over the past 30 days
    df['gap_frequency_30d'] = (df['gap'].abs() > 
