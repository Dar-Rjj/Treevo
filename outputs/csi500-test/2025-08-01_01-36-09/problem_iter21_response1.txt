```python
import pandas as pd
import numpy as np
from scipy.stats import zscore
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split

def heuristics_v2(df):
    # Adaptive Volatility
    df['return'] = df['close'].pct_change()
    df['volatility'] = df['return'].rolling(window=20).std().ewm(span=20, adjust=False).mean()

    # Dynamic Trend Following
    short_window = 50
    long_window = 200
    df['short_mavg'] = df['close'].rolling(window=short_window).mean()
    df['long_mavg'] = df['close'].rolling(window=long_window).mean()
    df['trend_signal'] = (df['short_mavg'] > df['long_mavg']).astype(int)
    df['roc'] = df['close'].pct_change(periods=14)
    df['trend_confirmed'] = df['trend_signal'] * df['roc']

    # Volume-Adjusted Momentum
    typical_price = (df['high'] + df['low'] + df['close']) / 3
    raw_money_flow = typical_price * df['volume']
    positive_money_flow = raw_money_flow.where(typical_price > typical_price.shift(1), 0)
    negative_money_flow = raw_money_flow.where(typical_price < typical_price.shift(1), 0)
    df['positive_mf_sum'] = positive_money_flow.rolling(window=14).sum()
    df['negative_mf_sum'] = negative_money_flow.abs().rolling(window=14).sum()
    df['mfi'] = 100 - (100 / (1 + (df['positive_mf_sum'] / df['negative_mf_sum'])))
    average_volume = df['volume'].rolling(window=20).mean()
    df['volume_ratio'] = df['volume'] / average_volume
    df['volume_adjusted_momentum'] = df['roc'] * df['volume_ratio']

    # RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))

    # Sentiment Analysis (Assume sentiment scores are available in the DataFrame)
    df['sentiment_factor'] = (df['sentiment_score'] - df['sentiment_score'].min()) / (df['sentiment_score'].max() - df['sent sentiment_score'].min())

    # Macroeconomic Data (Assume macroeconomic data is available in the DataFrame)
    df['macro_factor'] = (df['gdp_growth'] - df['gdp_growth'].min()) / (df['gdp_growth'].max() - df['gdp_growth'].min())

    # Sector-Specific Indicators (Assume P/E ratio and oil prices are available in the DataFrame)
    df['pe_ratio'] = df['price_to_earnings']
    df['oil_price_factor'] = (df['oil_price'] - df['oil_price'].min()) / (df['oil_price'].max() - df['oil_price'].min())

    # Combine all factors into a feature set
    features = df[['volatility', 'trend_confirmed', 'volume_adjusted_momentum', 'rsi', 'sentiment_factor', 'macro_factor', 'pe_ratio', 'oil_price_factor']].dropna()
    future_returns = df['close'].pct_change().shift(-1).loc[features.index]

    # Train a machine learning model to predict future returns
    X_train, X_test, y_train, y_test = train_test_split(features, future_returns, test_size=0.2, random_state=42)
    model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
    model.fit(X_train, y_train)

    # Generate weights for each factor
    weights = model.feature_importances_
    factor_values = features.values
    weighted_factors = np.dot(factor_values, weights)

    # Return the alpha factor
    df['alpha_factor'] = 0
    df.loc[features.index, 'alpha_factor'] = weighted_factors

    return df['alpha_factor']
```
