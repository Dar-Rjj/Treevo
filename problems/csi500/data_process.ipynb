{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1679a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "basepath = path.join(os.getcwd(), \"export_cn_ex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(\"csi500.txt\", \"r\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [line.split('\\t') for line in lines],\n",
    "    columns=['symbol', 'start_date', 'end_date']\n",
    ")\n",
    "\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df['end_date'] = pd.to_datetime(df['end_date'])\n",
    "\n",
    "mask = (df['start_date'] >= '2015-12-30') & (df['end_date'] <= '2020-01-01')\n",
    "stock_codes = np.unique(df[mask]['symbol'].tolist())\n",
    "\n",
    "print(len(stock_codes))\n",
    "\n",
    "dfs = []\n",
    "for stock_code in stock_codes:\n",
    "    fname = f\"{stock_code[:8]}.csv\"\n",
    "    fpath = os.path.join(basepath, fname)\n",
    "    if os.path.exists(fpath):\n",
    "        df = pd.read_csv(fpath, parse_dates=['date'])[['date','open','high','low','close','volume','amount']]\n",
    "        df = df[(df['date'] >= '2015-06-30') & (df['date'] <= '2020-01-31')]\n",
    "        df['stock_code'] = stock_code[:8]\n",
    "        dfs.append(df)\n",
    "\n",
    "train_df = pd.concat(dfs, ignore_index=True)\n",
    "train_df.set_index(['stock_code', 'date'], inplace=True)\n",
    "train_df.sort_index(inplace=True)\n",
    "\n",
    "train_df.to_csv(\"train_data.csv\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397927a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(\"csi500.txt\", \"r\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [line.split('\\t') for line in lines],\n",
    "    columns=['symbol', 'start_date', 'end_date']\n",
    ")\n",
    "\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df['end_date'] = pd.to_datetime(df['end_date'])\n",
    "\n",
    "mask = (df['start_date'] >= '2020-12-30') & (df['end_date'] <= '2024-01-01')\n",
    "stock_codes = np.unique(df[mask]['symbol'].tolist())\n",
    "\n",
    "print(len(stock_codes))\n",
    "\n",
    "dfs = []\n",
    "for stock_code in stock_codes:\n",
    "    fname = f\"{stock_code[:8]}.csv\"\n",
    "    fpath = os.path.join(basepath, fname)\n",
    "    if os.path.exists(fpath):\n",
    "        df = pd.read_csv(fpath, parse_dates=['date'])[['date','open','high','low','close','volume','amount']]\n",
    "        df = df[(df['date'] >= '2020-06-30') & (df['date'] <= '2024-01-31')]\n",
    "        df['stock_code'] = stock_code[:8]\n",
    "        dfs.append(df)\n",
    "\n",
    "test_df = pd.concat(dfs, ignore_index=True)\n",
    "test_df.set_index(['stock_code', 'date'], inplace=True)\n",
    "test_df.sort_index(inplace=True)\n",
    "\n",
    "test_df.to_csv(\"test_data.csv\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a17363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def heuristics_v2(df: pd.DataFrame) -> pd.Series:\n",
    "    # 1-day momentum: immediate price movement\n",
    "    momentum = df['close'] / df['close'].shift(1) - 1\n",
    "    \n",
    "    # Daily volatility: intraday range normalized by midpoint\n",
    "    volatility = (df['high'] - df['low']) / ((df['high'] + df['low']) / 2 + 1e-7)\n",
    "    \n",
    "    # Volatility-normalized momentum with volume confirmation\n",
    "    factor = (momentum / (volatility + 1e-7))\n",
    "    \n",
    "    return factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2dd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def heuristics_v2(df):\n",
    "    \"\"\"\n",
    "    Generate novel alpha factor combining multiple market dynamics:\n",
    "    - Asymmetric Volatility Momentum\n",
    "    - Volume-Weighted Range Breakout  \n",
    "    - Intraday Efficiency Momentum\n",
    "    - Liquidity-Adjusted Gap Reversal\n",
    "    - Regime-Adaptive Order Flow\n",
    "    \"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. Asymmetric Volatility Momentum\n",
    "    # Multi-timeframe momentum\n",
    "    mom_3 = data['close'].pct_change(3)\n",
    "    mom_10 = data['close'].pct_change(10)\n",
    "    mom_20 = data['close'].pct_change(20)\n",
    "    \n",
    "    # Upside volatility (positive returns only)\n",
    "    high_returns = (data['high'] / data['close'].shift(1) - 1).clip(lower=0)\n",
    "    upside_vol = high_returns.rolling(window=10, min_periods=5).std()\n",
    "    \n",
    "    # Downside volatility (negative returns only)  \n",
    "    low_returns = (data['low'] / data['close'].shift(1) - 1).clip(upper=0)\n",
    "    downside_vol = low_returns.rolling(window=10, min_periods=5).std()\n",
    "    \n",
    "    # Volatility ratio with smoothing\n",
    "    vol_ratio = (upside_vol + 1e-6) / (downside_vol + 1e-6)\n",
    "    vol_ratio_smooth = vol_ratio.rolling(window=5, min_periods=3).mean()\n",
    "    \n",
    "    # Momentum alignment check\n",
    "    momentum_aligned = ((mom_3 > 0) & (mom_10 > 0) & (mom_20 > 0)) | \\\n",
    "                      ((mom_3 < 0) & (mom_10 < 0) & (mom_20 < 0))\n",
    "    \n",
    "    # Combined asymmetric momentum\n",
    "    asym_momentum = mom_10 * vol_ratio_smooth * momentum_aligned.astype(float)\n",
    "    \n",
    "    # 2. Volume-Weighted Range Breakout\n",
    "    # Normalized trading range\n",
    "    daily_range = data['high'] - data['low']\n",
    "    avg_range_20 = daily_range.rolling(window=20, min_periods=10).mean()\n",
    "    normalized_range = daily_range / (avg_range_20 + 1e-6)\n",
    "    \n",
    "    # Volume cluster detection\n",
    "    vol_ma_20 = data['volume'].rolling(window=20, min_periods=10).mean()\n",
    "    high_volume = data['volume'] > (vol_ma_20 * 1.5)\n",
    "    \n",
    "    # Resistance from past high volume days\n",
    "    high_volume_highs = data['high'].where(high_volume).rolling(window=10, min_periods=5).max()\n",
    "    breakout_strength = (data['close'] - high_volume_highs) / (high_volume_highs + 1e-6)\n",
    "    \n",
    "    # Weighted breakout signal\n",
    "    range_breakout = breakout_strength * normalized_range * high_volume.astype(float)\n",
    "    \n",
    "    # 3. Intraday Efficiency Momentum\n",
    "    # Morning strength (Open to High)\n",
    "    morning_strength = (data['high'] - data['open']) / (data['open'] + 1e-6)\n",
    "    \n",
    "    # Afternoon efficiency (High to Close)\n",
    "    afternoon_efficiency = (data['close'] - data['high']) / (data['high'] + 1e-6)\n",
    "    \n",
    "    # Daily price efficiency ratio\n",
    "    efficiency_ratio = afternoon_efficiency / (np.abs(morning_strength) + 1e-6)\n",
    "    \n",
    "    # Pattern persistence\n",
    "    same_direction = ((morning_strength > 0) & (afternoon_efficiency > 0)) | \\\n",
    "                    ((morning_strength < 0) & (afternoon_efficiency < 0))\n",
    "    \n",
    "    efficiency_ma_5 = efficiency_ratio.rolling(window=5, min_periods=3).mean()\n",
    "    efficiency_momentum = efficiency_ratio - efficiency_ma_5\n",
    "    \n",
    "    intraday_momentum = efficiency_momentum * same_direction.astype(float)\n",
    "    \n",
    "    # 4. Liquidity-Adjusted Gap Reversal\n",
    "    # Opening gap\n",
    "    gap_pct = (data['open'] - data['close'].shift(1)) / (data['close'].shift(1) + 1e-6)\n",
    "    \n",
    "    # Effective spread proxy\n",
    "    effective_spread = data['amount'] / (data['volume'] + 1e-6)\n",
    "    spread_ma = effective_spread.rolling(window=10, min_periods=5).mean()\n",
    "    normalized_spread = effective_spread / (spread_ma + 1e-6)\n",
    "    \n",
    "    # Mean reversion logic\n",
    "    gap_reversal = -gap_pct * np.abs(gap_pct)\n",
    "    liquidity_reversal = gap_reversal / (normalized_spread + 1e-6)\n",
    "    \n",
    "    # 5. Regime-Adaptive Order Flow\n",
    "    # Volatility regime detection\n",
    "    true_range = np.maximum(data['high'] - data['low'], \n",
    "                           np.maximum(np.abs(data['high'] - data['close'].shift(1)),\n",
    "                                     np.abs(data['low'] - data['close'].shift(1))))\n",
    "    \n",
    "    vol_regime = true_range.rolling(window=10, min_periods=5).std()\n",
    "    regime_change = vol_regime.pct_change(3)\n",
    "    \n",
    "    # Directional volume accumulation\n",
    "    buying_days = data['close'] > data['open']\n",
    "    selling_days = data['close'] < data['open']\n",
    "    \n",
    "    signed_volume = data['volume'] * buying_days.astype(float) - data['volume'] * selling_days.astype(float)\n",
    "    cumulative_flow = signed_volume.rolling(window=10, min_periods=5).sum()\n",
    "    \n",
    "    # Regime-specific signal\n",
    "    regime_signal = cumulative_flow * regime_change * (regime_change > 0).astype(float)\n",
    "    \n",
    "    # Final factor combination with equal weights\n",
    "    factor = (0.2 * asym_momentum + \n",
    "              0.2 * range_breakout + \n",
    "              0.2 * intraday_momentum + \n",
    "              0.2 * liquidity_reversal + \n",
    "              0.2 * regime_signal)\n",
    "    \n",
    "    # Normalize the final factor\n",
    "    factor_normalized = (factor - factor.rolling(window=20, min_periods=10).mean()) / \\\n",
    "                       (factor.rolling(window=20, min_periods=10).std() + 1e-6)\n",
    "    \n",
    "    return factor_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7099df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IC: -0.0462177474\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# 读取合并后的数据\n",
    "train_df = pd.read_csv(\"train_data.csv\", parse_dates=['date'])\n",
    "train_df.set_index(['stock_code', 'date'], inplace=True)\n",
    "train_df.sort_index(inplace=True)\n",
    "\n",
    "# 计算每只股票的因子值\n",
    "train_df['factor'] = train_df.groupby('stock_code').apply(lambda g: heuristics_v2(g)).reset_index(level=0, drop=True)\n",
    "\n",
    "# 计算未来6日收益率\n",
    "train_df['future_return_6d'] = train_df.groupby('stock_code')['close'].shift(-20) / train_df['close'] - 1\n",
    "\n",
    "# 取所有日期\n",
    "start_date = pd.Timestamp('2016-01-01')\n",
    "end_date = pd.Timestamp('2020-01-01')\n",
    "all_dates = train_df.index.get_level_values('date').unique()\n",
    "all_dates = all_dates[(all_dates >= start_date) & (all_dates <= end_date)]\n",
    "ic_values = []\n",
    "\n",
    "for date in all_dates:\n",
    "    daily = train_df.xs(date, level='date')\n",
    "    factors = daily['factor']\n",
    "    returns = daily['future_return_6d']\n",
    "    mask = factors.notna() & returns.notna() & np.isfinite(factors) & np.isfinite(returns)\n",
    "    if mask.sum() >= 10:\n",
    "        ic, _ = pearsonr(factors[mask], returns[mask])\n",
    "        if not np.isnan(ic):\n",
    "            ic_values.append(ic)\n",
    "\n",
    "mean_ic = np.mean(ic_values)\n",
    "print(f\"Mean IC: {mean_ic:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66a3bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IC: -0.2266687174\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "# 读取合并后的数据\n",
    "test_df = pd.read_csv(\"test_data.csv\", parse_dates=['date'])\n",
    "test_df.set_index(['stock_code', 'date'], inplace=True)\n",
    "test_df.sort_index(inplace=True)\n",
    "\n",
    "# 计算每只股票的因子值\n",
    "test_df['factor'] = test_df.groupby('stock_code').apply(lambda g: heuristics_v2(g)).reset_index(level=0, drop=True)\n",
    "\n",
    "# 计算未来6日收益率\n",
    "test_df['future_return_6d'] = test_df.groupby('stock_code')['close'].shift(-20) / test_df['close'] - 1\n",
    "\n",
    "# 取所有日期\n",
    "start_date = pd.Timestamp('2021-01-01')\n",
    "end_date = pd.Timestamp('2024-01-01')\n",
    "all_dates = test_df.index.get_level_values('date').unique()\n",
    "all_dates = all_dates[(all_dates >= start_date) & (all_dates <= end_date)]\n",
    "ic_values = []\n",
    "\n",
    "for date in all_dates:\n",
    "    daily = test_df.xs(date, level='date')\n",
    "    factors = daily['factor']\n",
    "    returns = daily['future_return_6d']\n",
    "    mask = factors.notna() & returns.notna() & np.isfinite(factors) & np.isfinite(returns)\n",
    "    if mask.sum() >= 10:\n",
    "        ic, _ = pearsonr(factors[mask], returns[mask])\n",
    "        if not np.isnan(ic):\n",
    "            ic_values.append(ic)\n",
    "\n",
    "mean_ic = np.mean(ic_values)\n",
    "print(f\"Mean IC: {mean_ic:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StockPred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
